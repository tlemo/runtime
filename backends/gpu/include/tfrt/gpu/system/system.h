/*
 * Copyright 2021 The TensorFlow Runtime Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Define a few thin wrapper for GPU APIs.

#ifndef TFRT_GPU_SYSTEM_SYSTEM_H_
#define TFRT_GPU_SYSTEM_SYSTEM_H_

#include "tfrt/bef/bef_buffer.h"
#include "tfrt/gpu/device/device.h"
#include "tfrt/gpu/wrapper/blas_wrapper.h"
#include "tfrt/gpu/wrapper/wrapper.h"
#include "tfrt/host_context/async_value_ref.h"
#include "tfrt/support/forward_decls.h"
#include "tfrt/support/ref_count.h"

namespace tfrt {
class BEFFile;
class Function;
class Chain;
class ExecutionContext;
namespace gpu {

class GpuAllocator;
class GpuBuffer;
class GpuContext;
class GpuStream;

// A thin wrapper of TFRT callable GPU Function. The function should be
// generated by lhlo_gpu_to_tfrt_gpu. This class manages the lifetime of
// the GPU Function.
class Program {
 public:
  Program(BefBuffer&& file_buffer, llvm::StringRef function_name,
          HostContext* host);
  const Function* GetFunction() { return function_; }

 private:
  BefBuffer file_buffer_;

  // The ownership of this bef file isn't shared.
  RCReference<BEFFile> bef_file_;
  const Function* function_;
};

// A thin wrapper on top of low level GPU APIs. It provides convenient methods
// to  transfer data to&from GPU devices, manage streams and execute GPU
// functions that are lowered from HLO.
// TODO(fishx): Assess if we should expose GPU Event as well.
class System {
 public:
  // Initialize all GPU devices that are connected. It uses <prefix><ordinal> as
  // the name of each GPU devices.
  static AsyncValueRef<System> Initialize(wrapper::Platform platform,
                                          llvm::StringRef prefix,
                                          HostContext* host);

  // Instantiates a System without initializing the GPU platform or devices.
  static AsyncValueRef<System> Instantiate(HostContext* host);

  // Create a new stream for given gpu_ordinal. Don't deallocate the stream if
  // there are pending kernels that haven't been scheduled on the stream. This
  // can be verified by checking all chains returned by this class.
  AsyncValueRef<GpuStream> CreateStream(ExecutionContext& exec_ctx,
                                        int gpu_ordinal);

  // TODO(fishx): Introduce method to synchronize two streams.

  // Create a new GPU memory allocator associated with the provided stream's
  // context.
  AsyncValueRef<GpuAllocator> CreateAllocator(ExecutionContext& exec_ctx,
                                              AsyncValueRef<GpuStream> stream);

  // Allocate a new GPU buffer using the provided allocator associated with the
  // GPU device. Return an async value because lowered tfrt function is an
  // asynchronous function which requires all arguments are async value.
  AsyncValueRef<GpuBuffer> Allocate(ExecutionContext& exec_ctx,
                                    AsyncValueRef<GpuStream> stream,
                                    AsyncValueRef<GpuAllocator> allocator,
                                    size_t size);

  // Transfer data from host to device. The output chain is ready when the copy
  // has been schedule on the stream. When the chain is ready we cannot
  // deallocate the src buffer since the copy hasn't finished yet.
  // TODO(fishx):  Introduce another chain to track when we can deallocate src
  // buffer.
  AsyncValueRef<Chain> TransferToDevice(ExecutionContext& exec_ctx,
                                        AsyncValueRef<GpuStream> stream,
                                        AsyncValueRef<GpuBuffer> dst,
                                        ArrayRef<uint8_t> src,
                                        AsyncValueRef<Chain> chain);

  // Transfer data from device to host. The output chain is ready when the copy
  // is finished.
  // TODO(fishx): Consider introduce another chain to indicate the copy has been
  // schedule on the stream.
  AsyncValueRef<Chain> TransferFromDevice(ExecutionContext& exec_ctx,
                                          AsyncValueRef<GpuStream> stream,
                                          MutableArrayRef<uint8_t> dst,
                                          AsyncValueRef<GpuBuffer> src,
                                          AsyncValueRef<Chain> chain);

  // TODO(fishx): Introduce method for d2d data transfer.

  // Execute the lowered GPU Function on given stream. The output chain is ready
  // when the all gpu kernels have been dispatched on the stream.
  AsyncValueRef<Chain> Execute(ExecutionContext& exec_ctx, Program& program,
                               AsyncValueRef<GpuStream> stream,
                               ArrayRef<AsyncValueRef<GpuBuffer>> inputs,
                               ArrayRef<AsyncValueRef<GpuBuffer>> outputs,
                               AsyncValueRef<Chain> chain);
};

}  // namespace gpu
}  // namespace tfrt

#endif  // TFRT_GPU_SYSTEM_SYSTEM_H_
